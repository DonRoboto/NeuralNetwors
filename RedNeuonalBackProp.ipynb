{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RedNeuonalBackProp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMtU4V5i1+803Few5yAIMjv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonRoboto/RedesNeuronales/blob/master/RedNeuonalBackProp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T_SnNxhlmL8",
        "colab_type": "text"
      },
      "source": [
        "Red Neuoronal Densa entrenada con Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwjtc0ORlo6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPEoOPiCmMRZ",
        "colab_type": "text"
      },
      "source": [
        "Esta red neuronal densa está compuesta por una capa de 2 entradas ($x_1$ y $x_2$), una capa oculta con 3 neuronas con función de activación sigmoide y una capa de salida con una sola neurona con función de activación sigmoide. Esta función de activación se define como:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f012Cb-mmOHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoide(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nnNYpLpmUUN",
        "colab_type": "text"
      },
      "source": [
        "La función sigmoide tiene una derivada que está expresada en términos de la misma función, esto es, \n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\sigma (z)}{\\partial z} = \\sigma(z) (1 - \\sigma(z))\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3A1AWkOmU3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def derivada_sigmoide(x):\n",
        "    return np.multiply(sigmoide(x), (1.0 - sigmoide(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD8hjsvzmYbd",
        "colab_type": "text"
      },
      "source": [
        "Podemos ver la operación XOR como una tarea de clasificación binaria a partir de 2 entradas. Por lo tanto, usaremos la función de pérdida de entropía cruzada binaria:\n",
        "\n",
        "$$\n",
        "ECB(\\mathbf{y}, \\mathbf{\\hat{y}})  = -\\sum_{i=1}^N \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iRKFDSkmiCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def entropia_cruzada_binaria(y, p):\n",
        "    p[p == 0] = np.nextafter(0., 1.)\n",
        "    p[p == 1] = np.nextafter(1., 0.)\n",
        "    return -(np.log(p[y == 1]).sum() + np.log(1 - p[y == 0]).sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIA7ElvomopQ",
        "colab_type": "text"
      },
      "source": [
        "Calcularemos la exactitud para medir el rendimiento del modelo aprendido por la red neuronal densa:\n",
        "\n",
        "$$\n",
        "exactitud = \\frac{correctos}{total}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2XrfEmbmwST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exactitud(y, y_predicha):\n",
        "    return (y == y_predicha).mean() * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gq7cnVIm3Wd",
        "colab_type": "text"
      },
      "source": [
        "Definimos la función que propaga hacia adelante una entrada $\\mathbf{x}^{i}$. Como la red está compuesta de 2 capas densas (1 oculta y 1 de salida), tenemos 2 matrices de pesos con sus correspondientes vectores de sesgos $\\{\\mathbf{W}^{\\{1\\}}, \\mathbf{b}^{\\{1\\}}\\}$ y $\\{\\mathbf{W}^{\\{2\\}}, \\mathbf{b}^{\\{2\\}}\\}$ de la capa oculta y la capa de salida respectivamente. Así, podemos llevar a cabo la propagación hacia adelante en esta red de la siguiente manera:\n",
        "\n",
        "$$\n",
        "\t\\begin{split}\n",
        "\t\t\t\t\\mathbf{a}^{\\{1\\}} & =  \\mathbf{x}^{(i)} \\\\\n",
        "\t\t\t\t\\mathbf{z}^{\\{2\\}} & =  \\mathbf{W}^{\\{1\\}} \\cdot \\mathbf{a}^{\\{1\\}} + \\mathbf{b}^{\\{1\\}}\\\\\n",
        "\t\t\t\t\\mathbf{a}^{\\{2\\}} & =  \\sigma(\\mathbf{z}^{\\{2\\}}) \\\\\n",
        "\t\t\t\t\\mathbf{z}^{\\{3\\}} & =  \\mathbf{W}^{\\{2\\}} \\cdot \\mathbf{a}^{\\{2\\}}  + \\mathbf{b}^{\\{2\\}}\\\\\n",
        "\t\t\t\t\\mathbf{a}^{\\{3\\}} & =  \\sigma(\\mathbf{z}^{\\{3\\}})\\\\\n",
        "\t\t\t\t\\hat{y}^{(i)} & =  \\mathbf{a}^{\\{3\\}}\n",
        "\t\t\t\\end{split}\n",
        "      $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdhyJ-Djm47B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hacia_adelante(x, W1, b1, W2, b2, W3, b3, W4, b4):\n",
        "  z2 = np.dot(W1.T, x[:, np.newaxis]) + b1\n",
        "  a2 = sigmoide(z2)  \n",
        "  z3 = np.dot(W2.T, a2) + b2\n",
        "  a3 = sigmoide(z3)\n",
        "  z4 = np.dot(W3.T, a3) + b3\n",
        "  a4 = sigmoide(z4)\n",
        "  z5 = np.dot(W4.T, a4) + b4\n",
        "    \n",
        "  y_hat = sigmoide(z5)\n",
        "  \n",
        "  return z2, a2, z3, a3, z4, a4, z5, y_hat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhWipi9ZnXnh",
        "colab_type": "text"
      },
      "source": [
        "Definimos la función para entrenar nuestra red neuronal usando gradiente descendente. Para calcular el gradiente de la función de pérdida respecto a los pesos y sesgos en cada capa empleamos el algoritmo de retropropagación de errores.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvweYD_YnEJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retropropagacion(X, y, alpha = 0.01, n_epocas = 100, n_ocultas = 10):\n",
        "    n_ejemplos = X.shape[0]\n",
        "    n_entradas = X.shape[1]\n",
        "    \n",
        "    # Inicialización de las matrices de pesos W y V\n",
        "    W1 = np.sqrt(1.0 / n_entradas) * np.random.randn(n_entradas, n_ocultas)\n",
        "    b1 = np.zeros((n_ocultas, 1))\n",
        "    \n",
        "    W2 = np.sqrt(1.0 / n_ocultas) * np.random.randn(n_ocultas, n_ocultas)\n",
        "    b2 = np.zeros((1, 1))\n",
        "    \n",
        "    W3 = np.sqrt(1.0 / n_ocultas) * np.random.randn(n_ocultas, n_ocultas)\n",
        "    b3 = np.zeros((1, 1))\n",
        "\n",
        "    W4 = np.sqrt(1.0 / n_ocultas) * np.random.randn(n_ocultas, 1)\n",
        "    b4 = np.zeros((1, 1))\n",
        "    \n",
        "    perdidas = np.zeros((n_epocas))\n",
        "    exactitudes = np.zeros((n_epocas))\n",
        "    y_predicha = np.zeros((y.shape))\n",
        "    for i in range(n_epocas):\n",
        "        for j in range(n_ejemplos):\n",
        "            z2, a2, z3, a3, z4, a4, z5, y_hat = hacia_adelante(X[j], W1, b1, W2, b2, W3, b3, W4, b4)\n",
        "\n",
        "            # cálculo de gradiente para W3 por retropropagación\n",
        "            delta5 = (y_hat - y[j]) * derivada_sigmoide(z5)\n",
        "            W4 = W4 - alpha * np.outer(a4, delta5)\n",
        "            b4 = b4 - alpha * delta5\n",
        "\n",
        "            # cálculo de gradiente para W3 por retropropagación\n",
        "            delta4 = (y_hat - y[j]) * derivada_sigmoide(z4)\n",
        "            W3 = W3 - alpha * np.outer(a3, delta4)\n",
        "            b3 = b3 - alpha * delta4\n",
        "            \n",
        "            # cálculo de gradiente para W2 por retropropagación\n",
        "            delta3 = (y_hat - y[j]) * derivada_sigmoide(z3)\n",
        "            W2 = W2 - alpha * np.outer(a2, delta3)\n",
        "            b2 = b2 - alpha * delta3\n",
        "\n",
        "            # cálculo de gradiente para W1 por retropropagación\n",
        "            delta2 = np.dot(W2, delta3) * derivada_sigmoide(z2)\n",
        "            W1 = W1 - alpha * np.outer(X[j], delta2)\n",
        "            b1 = b1 - alpha * delta2\n",
        "\n",
        "            y_predicha[j] = y_hat\n",
        "            \n",
        "        # calcula error en época\n",
        "        perdidas[i] = entropia_cruzada_binaria(y, y_predicha)\n",
        "        exactitudes[i] = exactitud(y, np.round(y_predicha))\n",
        "        if i%10==0:\n",
        "          print('Epoch {0}: Error = {1} Exactitud = {2}'.format(i, \n",
        "                                                              perdidas[i], \n",
        "                                                              exactitudes[i]))\n",
        "\n",
        "    return W1, W2, W3, W4, b1, b2, b3, b4, perdidas, exactitudes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9SYqDosnhFV",
        "colab_type": "text"
      },
      "source": [
        "# ejemplo (XNOR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esvDLE0OntcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[1, 0, 0, 1]]).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJM2vZNHn181",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, entrenamos nuestra red con estos ejemplos por 200 épocas usando una tasa de aprendizaje $\\alpha = 1.0$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS0A9tVFn4WY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa4cbba0-a0ab-4aa3-d456-041233285f06"
      },
      "source": [
        "np.random.seed(0)\n",
        "W1t, W2t, W3t, W4t, b1t, b2t, b3t, b4t, perdidas, exactitudes = retropropagacion(X, \n",
        "                                                 y, \n",
        "                                                 alpha = 1.0, \n",
        "                                                 n_epocas = 1000,\n",
        "                                                 n_ocultas = 10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Error = 3.2875035895537 Exactitud = 50.0\n",
            "Epoch 10: Error = 4.434426346777828 Exactitud = 50.0\n",
            "Epoch 20: Error = 4.488684454264117 Exactitud = 50.0\n",
            "Epoch 30: Error = 4.506652238938841 Exactitud = 50.0\n",
            "Epoch 40: Error = 4.515809657298049 Exactitud = 50.0\n",
            "Epoch 50: Error = 4.520692804648317 Exactitud = 50.0\n",
            "Epoch 60: Error = 4.521813116853505 Exactitud = 50.0\n",
            "Epoch 70: Error = 4.515807370689476 Exactitud = 50.0\n",
            "Epoch 80: Error = 4.470088591170661 Exactitud = 50.0\n",
            "Epoch 90: Error = 4.0942306258209324 Exactitud = 25.0\n",
            "Epoch 100: Error = 3.396474975982227 Exactitud = 25.0\n",
            "Epoch 110: Error = 2.960848350766512 Exactitud = 75.0\n",
            "Epoch 120: Error = 2.8297571494580733 Exactitud = 75.0\n",
            "Epoch 130: Error = 2.7822231744940575 Exactitud = 75.0\n",
            "Epoch 140: Error = 2.763050432656656 Exactitud = 75.0\n",
            "Epoch 150: Error = 2.754944990361451 Exactitud = 75.0\n",
            "Epoch 160: Error = 2.7516815284954808 Exactitud = 75.0\n",
            "Epoch 170: Error = 2.7507539940515287 Exactitud = 75.0\n",
            "Epoch 180: Error = 2.7509998588727234 Exactitud = 75.0\n",
            "Epoch 190: Error = 2.751808070793402 Exactitud = 75.0\n",
            "Epoch 200: Error = 2.7528287282485326 Exactitud = 75.0\n",
            "Epoch 210: Error = 2.753852962698488 Exactitud = 75.0\n",
            "Epoch 220: Error = 2.754757046581039 Exactitud = 75.0\n",
            "Epoch 230: Error = 2.755473206221647 Exactitud = 75.0\n",
            "Epoch 240: Error = 2.7559723407904233 Exactitud = 75.0\n",
            "Epoch 250: Error = 2.7562523298510975 Exactitud = 75.0\n",
            "Epoch 260: Error = 2.7563291838229924 Exactitud = 75.0\n",
            "Epoch 270: Error = 2.756229936484901 Exactitud = 75.0\n",
            "Epoch 280: Error = 2.7559869355354465 Exactitud = 75.0\n",
            "Epoch 290: Error = 2.755633473366162 Exactitud = 75.0\n",
            "Epoch 300: Error = 2.755200732063461 Exactitud = 75.0\n",
            "Epoch 310: Error = 2.7547159369883576 Exactitud = 75.0\n",
            "Epoch 320: Error = 2.7542015184559214 Exactitud = 75.0\n",
            "Epoch 330: Error = 2.7536750235067116 Exactitud = 75.0\n",
            "Epoch 340: Error = 2.7531495138759605 Exactitud = 75.0\n",
            "Epoch 350: Error = 2.7526342216239845 Exactitud = 75.0\n",
            "Epoch 360: Error = 2.752135290547919 Exactitud = 75.0\n",
            "Epoch 370: Error = 2.7516564910876316 Exactitud = 75.0\n",
            "Epoch 380: Error = 2.7511998472424146 Exactitud = 75.0\n",
            "Epoch 390: Error = 2.7507661512388033 Exactitud = 75.0\n",
            "Epoch 400: Error = 2.7503553654463433 Exactitud = 75.0\n",
            "Epoch 410: Error = 2.7499669239367646 Exactitud = 75.0\n",
            "Epoch 420: Error = 2.7495999514121445 Exactitud = 75.0\n",
            "Epoch 430: Error = 2.749253417941377 Exactitud = 75.0\n",
            "Epoch 440: Error = 2.7489262462689488 Exactitud = 75.0\n",
            "Epoch 450: Error = 2.748617385884544 Exactitud = 75.0\n",
            "Epoch 460: Error = 2.7483258654714438 Exactitud = 75.0\n",
            "Epoch 470: Error = 2.7480508333062397 Exactitud = 75.0\n",
            "Epoch 480: Error = 2.747791593989899 Exactitud = 75.0\n",
            "Epoch 490: Error = 2.747547649867922 Exactitud = 75.0\n",
            "Epoch 500: Error = 2.747318757166142 Exactitud = 75.0\n",
            "Epoch 510: Error = 2.7471050112905573 Exactitud = 75.0\n",
            "Epoch 520: Error = 2.7469069852065986 Exactitud = 75.0\n",
            "Epoch 530: Error = 2.7467259644403303 Exactitud = 75.0\n",
            "Epoch 540: Error = 2.7465643639862876 Exactitud = 75.0\n",
            "Epoch 550: Error = 2.7464265059595734 Exactitud = 75.0\n",
            "Epoch 560: Error = 2.746320161665216 Exactitud = 75.0\n",
            "Epoch 570: Error = 2.746259849830554 Exactitud = 75.0\n",
            "Epoch 580: Error = 2.7462745791744805 Exactitud = 75.0\n",
            "Epoch 590: Error = 2.746428150640917 Exactitud = 75.0\n",
            "Epoch 600: Error = 2.7468788316342745 Exactitud = 75.0\n",
            "Epoch 610: Error = 2.748065013303158 Exactitud = 75.0\n",
            "Epoch 620: Error = 2.7512787316348755 Exactitud = 75.0\n",
            "Epoch 630: Error = 2.7625138103373157 Exactitud = 75.0\n",
            "Epoch 640: Error = 2.803385084343228 Exactitud = 75.0\n",
            "Epoch 650: Error = 2.711381053913623 Exactitud = 50.0\n",
            "Epoch 660: Error = 2.417995907565225 Exactitud = 75.0\n",
            "Epoch 670: Error = 2.059737858408373 Exactitud = 50.0\n",
            "Epoch 680: Error = 0.5964641264500741 Exactitud = 100.0\n",
            "Epoch 690: Error = 0.38009564590132827 Exactitud = 100.0\n",
            "Epoch 700: Error = 0.2991062656200497 Exactitud = 100.0\n",
            "Epoch 710: Error = 0.2537799827545194 Exactitud = 100.0\n",
            "Epoch 720: Error = 0.22393095482474068 Exactitud = 100.0\n",
            "Epoch 730: Error = 0.20241738857786068 Exactitud = 100.0\n",
            "Epoch 740: Error = 0.18598218372977626 Exactitud = 100.0\n",
            "Epoch 750: Error = 0.1728968618403953 Exactitud = 100.0\n",
            "Epoch 760: Error = 0.16214205690292566 Exactitud = 100.0\n",
            "Epoch 770: Error = 0.15306187317108896 Exactitud = 100.0\n",
            "Epoch 780: Error = 0.14519471311277887 Exactitud = 100.0\n",
            "Epoch 790: Error = 0.1381883908702871 Exactitud = 100.0\n",
            "Epoch 800: Error = 0.1318168180964322 Exactitud = 100.0\n",
            "Epoch 810: Error = 0.1261087846873686 Exactitud = 100.0\n",
            "Epoch 820: Error = 0.12118489929550616 Exactitud = 100.0\n",
            "Epoch 830: Error = 0.1169557364590139 Exactitud = 100.0\n",
            "Epoch 840: Error = 0.11325956558619699 Exactitud = 100.0\n",
            "Epoch 850: Error = 0.10997212385071835 Exactitud = 100.0\n",
            "Epoch 860: Error = 0.10700762878368839 Exactitud = 100.0\n",
            "Epoch 870: Error = 0.10430614300886777 Exactitud = 100.0\n",
            "Epoch 880: Error = 0.10182434514337266 Exactitud = 100.0\n",
            "Epoch 890: Error = 0.09952981238660785 Exactitud = 100.0\n",
            "Epoch 900: Error = 0.09739757505846872 Exactitud = 100.0\n",
            "Epoch 910: Error = 0.09540803266765197 Exactitud = 100.0\n",
            "Epoch 920: Error = 0.09354571709415854 Exactitud = 100.0\n",
            "Epoch 930: Error = 0.09179866411133245 Exactitud = 100.0\n",
            "Epoch 940: Error = 0.09015833569127626 Exactitud = 100.0\n",
            "Epoch 950: Error = 0.08862004412097663 Exactitud = 100.0\n",
            "Epoch 960: Error = 0.08718296649759111 Exactitud = 100.0\n",
            "Epoch 970: Error = 0.08584544987950002 Exactitud = 100.0\n",
            "Epoch 980: Error = 0.08459168399842124 Exactitud = 100.0\n",
            "Epoch 990: Error = 0.08339075029702044 Exactitud = 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxVgqDT3n-3C",
        "colab_type": "text"
      },
      "source": [
        "Graficamos el valor de la pérdida y la exactitud en cada época para ver el comportamiento de nuestra red durante el entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TollJWBPoBCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0a6adcb9-0755-44ae-d09b-1644d81e9558"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.arange(perdidas.size), perdidas, label='ECB')\n",
        "plt.plot(np.arange(exactitudes.size), exactitudes, label='Exactitud')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4LG2BeOob0G",
        "colab_type": "text"
      },
      "source": [
        "Probamos nuestro modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sARPHxlMod8M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "5ad02d3c-4bca-43f1-851a-0e133ecfbb40"
      },
      "source": [
        "for i in range(4):\n",
        "  z2, a2, z3, a3, z4, a4, z5, y_hat = hacia_adelante(X[i], W1t, b1t, W2t, b2t, W3t, b3t, W4t, b4t)\n",
        "  \n",
        "  if y_hat<0.5:\n",
        "    y_hat_label = 0\n",
        "  else:\n",
        "    y_hat_label = 1  \n",
        "  \n",
        "  print(y[i],y_hat_label)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] 1\n",
            "[0] 0\n",
            "[0] 0\n",
            "[1] 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}