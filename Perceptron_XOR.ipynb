{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron_XOR.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonRoboto/RedesNeuronales/blob/master/Perceptron_XOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPkREavvTlRP",
        "colab_type": "text"
      },
      "source": [
        "## Aproximando funciones no lineales: XOR ($\\oplus$)\n",
        "Minsky y Papert mostraron que una neurona del tipo LTU no puede aproximar de forma precisa una función no lineal como la compuerta XOR ($\\oplus$):\n",
        "\n",
        "\n",
        "| $x_1$ | $x_2$ | $y$\n",
        "| ------------- |:-------------:| -----:|\n",
        "|0 |0 |0|\n",
        "|0 |1 |1|\n",
        "|1 |0 |1|\n",
        "|1 |1 |0|\n",
        "\n",
        "Sin embargo, es posible aproximar este tipo  combinando múltiples LTU conectadas en red. Por ejemplo, es posible llevar a cabo la operación XOR con operaciones OR, AND y NAND:\n",
        "\n",
        "$\n",
        "\t  x_1 \\mathbin{\\oplus} x_2 = (x_1 \\lor x_2) \\land \\neg(x_1 \\land x_2)\n",
        "\t$  \n",
        "\n",
        "Esto lo llevamos a cabo con la siguiente función:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMhY_QU1Tuxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu0GmEFwUOEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def escalon(z):\n",
        "    if z > 0.0:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hrQjEeqToPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multicapa(x, W1, b1, W2, b2, W3, b3):\n",
        "  escv = np.vectorize(escalon)\n",
        "  c1 = escv(np.dot(W1.T, x) + b1)\n",
        "  c2 = escv(np.dot(W2.T, c1) + b2)\n",
        "  c3 = escv(np.dot(W3.T, c2) + b3)\n",
        "  return c3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE7SVcTmT9zO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#datos de entrada\n",
        "X = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an-4lzsaVA08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resultado esperado\n",
        "y_xnor = np.array([1., 0., 0., 1.])\n",
        "\n",
        "#pesos y sesgos para cada compuerta\n",
        "#OR y NAND\n",
        "W1 = np.array([[10, -10], [10, -10]])\n",
        "b1 = np.array([-5, 15])\n",
        "\n",
        "#AND\n",
        "W2 = np.array([[10], [10]])\n",
        "b2 = np.array([-15])\n",
        "\n",
        "#NOT\n",
        "W3 = np.array([[-1, -1]])\n",
        "b3 = np.array([1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7FXieqRVDMP",
        "colab_type": "code",
        "outputId": "cd708049-95fb-486b-e094-a0a1d32eff37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "print('W_1 = [{0}{1}], b_1 = {2}'.format(W1[0, :], W1[1, :], b1))\n",
        "print('W_2 = [{0}{1}], b_2 = {2}'.format(W2[0], W2[1], b2))\n",
        "print('W_3 = [{0}], b_3 = {1}'.format(W3[0], b3))\n",
        "\n",
        "print('-----------------------------')\n",
        "print('x_1 \\tx_2 \\ty\\ty_hat')\n",
        "print('-----------------------------')\n",
        "for i in range(X.shape[0]):\n",
        "  y_hat = multicapa(X[i], W1, b1, W2, b2, W3, b3)\n",
        "  print('{0}\\t{1}\\t{2}\\t{3}'.format(X[i, 0], X[i, 1], y_xnor[i], y_hat[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W_1 = [[ 10 -10][ 10 -10]], b_1 = [-5 15]\n",
            "W_2 = [[10][10]], b_2 = [-15]\n",
            "W_3 = [[-1 -1]], b_3 = [1]\n",
            "-----------------------------\n",
            "x_1 \tx_2 \ty\ty_hat\n",
            "-----------------------------\n",
            "0.0\t0.0\t1.0\t1.0\n",
            "0.0\t1.0\t0.0\t0.0\n",
            "1.0\t0.0\t0.0\t0.0\n",
            "1.0\t1.0\t1.0\t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}